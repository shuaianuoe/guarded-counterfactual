# Guarded-counterfactual

This is the code repository for guarded counterfactual (Paper ID: SIGMOD-709).

The codes are build upon [Carla](https://github.com/carla-recourse/CARLA), which is a popular python library to benchmark counterfactual explanations. 

In order to successfully run the code, you must successfully install cerla via pip

```
pip install carla-recourse
```

We should also configure a configuration file. The exact meaning of each parameter has been noted in `config.yaml`.

The original dataset can be found in the `datasets` folder.

## Section 1:  test the counterfactual quality

We should first set privacy to False in `config.yaml`.

To test our proposed algorithms, run below script:
```
python test_batch.py
```

To test the compared methods (You can specify the methods you want to test in  `config.yaml`), run below script:
```
python test_competitors.py
```

To test our proposed streaming algorithms, run below script:
```
python test_stream.py
```

## Section 2: test  model attacks

Set privacy to True in `config.yaml`.

Based on the guarded counterfactual, execute the following command to generate an adversary for attacking the model's training set:
```
python test_batch.py
```

Based on the counterfactuals generated by compared methods, execute the following command to generate an adversary for attacking the model's training set:
```
python test_competitors.py
```

Once the training set is prepared, run the script below:
```
python test_privacy.py
```

We can observe the performance of the surrogate model.
