# Guarded-counterfactual

This is the code repository for "Counterfactual Explanation at Will, with Zero Privacy Leakage".

___
The codes are build upon Carla, which is a popular python library to benchmark counterfactual explanations. 

To successfully run the code, we have already placed the Carla source code in the repository.

At the same time, to ensure smooth execution and avoid any potential package incompatibility issues, we strongly recommend using a fresh virtual environment

Here is an example of creating a new environment named `gc` with Python version 3.9.7:

```
conda create --name gc python=3.9.7
```

Then, activate the newly created environment `gc`.

```
activate gc
```

___


After activating the virtual environment, we first need to install the necessary packages, which are specified in `requirements.txt`. Run below code:

```
pip install -r requirements.txt
```

If the speed is too slow, consider specifying a dedicated mirror.
```
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/
```
___


Now we can start running the code. First, we should also configure a configuration file. The exact meaning of each parameter has been noted in `config.yaml`.

The original dataset can be found in the `datasets` folder. All the processed datasets are read by Carla.

Note that all the scripts should run on Windows 10/Ubuntu 14.04 and later systems.

## Section 1:  test the counterfactual quality

We should first set privacy to False in `config.yaml`.

To test our proposed algorithms, run below script:
```
python test_batch.py
```

The first run of the code will train the model, and the second run will generate explanations. (For convenience, we have already included the model corresponding to the loan dataset.

To test the compared methods (You can specify the methods you want to test in  `config.yaml`), run below script:
```
python test_competitors.py
```

### Noteï¼šwe can also test some additional features.

To test our proposed streaming algorithms, set cf_method to 'our' in `config.yaml`, then run below script:
```
python test_stream.py
```

Testing other variants is also simple. For instance, if you want to test maxmin and maxsum, set cf_method to 'max-sum' or 'max-min' in `config.yaml`, then run below script:
```
python test_max_min_sum.py
```


## Section 2: test defending model attacks

Set privacy to True and set cf_method to our in `config.yaml`.

Based on the guarded counterfactual, execute the following command to generate an adversary for attacking the model's training set:
```
python test_batch.py
```

Based on the counterfactuals generated by compared methods (set cf_method to other methods in `config.yaml`), execute the following command to generate an adversary for attacking the model's training set:
```
python test_competitors.py
```

Once the training set is prepared, run the script below:
```
python test_privacy.py
```

We can observe the performance of the surrogate model.
